# AI Wisdom Package

This package is responsible for generating the final, comprehensive context that the `AIEngine` uses to form its responses. It acts as the bridge between raw data/strategy and the final prompt, ensuring the LLM has all the information it needs, formatted correctly for the specific task.

## Core Components

### `context_coordinator.py`
This module acts as a simple router for context generation. Based on the `approach` defined in the strategy (e.g., `roleplay_active` vs. `comprehensive`), it directs the request to the appropriate context builder.

### `wisdom_engine.py`
This is the primary context builder for all standard (OOC) and database queries. It receives the structured query results and the query strategy, then uses the `PromptLibrary` to assemble a precise and detailed prompt for the `AIEngine`.

### `roleplay_context_builder.py`
This is the specialized context builder for immersive roleplay scenarios. It takes the strategy generated by the `AttentionEngine` and weaves together all the necessary context:
- Character relationships and history.
- The current scene and setting (including DGM context).
- The specific emotional tone and style required.
- The conversation history.
- Any relevant database knowledge.

The output is a rich, detailed prompt that guides the `AIEngine` in generating a high-quality, in-character roleplay response.

### `structured_content_retriever.py`
This is the unified data retrieval module. It takes the query object from the `StructuredQueryDetector` and orchestrates the retrieval of content from the database, coordinating with the `LogicEngine` for general queries.

### `prompt_builder.py`
This module contains the `PromptLibrary`, a centralized collection of prompt-generation functions for standard queries. It separates the prompt *wording* from the orchestration logic, creating a cleaner, more modular architecture. For example, it has specific functions to build prompts for synthesizing comprehensive information (`build_comprehensive_prompt`) or for telling a narrative story from logs (`build_logs_prompt`). 